{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc41b928-0ab2-4f59-92cd-cf6dc49c2e5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Differentiable Fluid Dynamics on TPUs\n",
    "\n",
    "This workflow serves as a \"conversion kit\" for [Computational Fluid Dynamics](https://en.wikipedia.org/wiki/Computational_fluid_dynamics) researchers. It demonstrates that you can keep their Python/NumPy syntax while unlocking Supercomputer-grade fluid dynamics an [Tensor Processing Units](https://en.wikipedia.org/wiki/Tensor_Processing_Unit). This is a complete, cell-by-cell workflow.\n",
    "\n",
    "## The Setup: Physics & Parameters\n",
    "\n",
    "We start by simulating [Von Kármán Vortex Shedding](https://en.wikipedia.org/wiki/K%C3%A1rm%C3%A1n_vortex_street) (flow past a cylinder); first using the typical workflow, then the [JAX](https://docs.jax.dev/) equivalent to run on any attached TPU. The resolution on the grid are course enough for you a to test on a CPU and can be adjusted to compare the performance once you have access to a TPU. Not that very fine grids will likely crash a CPU or suffer extremely long running times. \n",
    "\n",
    "Upto this point is a side-by-side performance comparison of the computational power of JAX-on-TPU vs numpy-on-CPU for equivalent modeling.\n",
    "\n",
    "We next look at some advantages that are unique to JAX. By leveraging the built-in differentiation in JAX we're able to \"reverse\" the simulation and home in on a cross-sectional profile that reduces turbulence (what CFD modelers are most interested in). This essentially automates your iterations through different cross sections.\n",
    "\n",
    "## Physics Parameters:\n",
    "\n",
    "- Grid: 400 $\\times$ 100 (High enough to see eddies, small enough to run quickly for the demo)\n",
    "- Reynolds Number: ~80 (The \"Unsteady\" regime where vortices spontaneously shed)\n",
    "- Lattice: D2Q9 (Standard 9-velocity model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9b185-1ec7-4ef9-b619-5049251c9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install JAX for TPU\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if we are in a TPU environment and install the correct version\n",
    "try:\n",
    "    import jax\n",
    "    print(\"JAX is already installed.\")\n",
    "except ImportError:\n",
    "    # This is the specific command for Cloud TPU VMs\n",
    "    print(\"Installing JAX for TPU...\")\n",
    "    !pip install -U \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1ceb8-f571-422d-889f-f7298b62dd75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verify we are on TPU\n",
    "print(f\"Target Device: {jax.devices()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fa5298-5f89-4810-b61e-7026a0f96a1e",
   "metadata": {},
   "source": [
    "## The Physics Constants (Shared)\n",
    "\n",
    "We define the physics once so the comparison is mathematically exact.\n",
    "\n",
    "**Note: The grid is deliberately coarse so you can begin your experiment on a CPU. Experiment much higher values for NX and NY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a518288-0b00-4dbe-950f-e49bbb37c179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Domain Constants ---\n",
    "NX = 400   # Width\n",
    "NY = 100   # Height\n",
    "R = NY // 9  # Cylinder Radius\n",
    "CX, CY = NX // 4, NY // 2  # Cylinder coordinates\n",
    "\n",
    "# --- Physics Constants ---\n",
    "# We tune these for a Reynolds Number ~80 to get vortex shedding\n",
    "U0 = 0.05             # Inflow velocity (Mach < 0.1 for stability)\n",
    "rho0 = 1.0            # Rest density\n",
    "Re = 80.0             # Reynolds number\n",
    "# Viscosity derived from Re: nu = U * D / Re\n",
    "nu = U0 * (2 * R) / Re\n",
    "# Relaxation time (tau) derived from viscosity: nu = (tau - 0.5)/3\n",
    "tau = 3.0 * nu + 0.5 \n",
    "\n",
    "print(f\"Simulating Reynolds Number: {Re}\")\n",
    "print(f\"Computed Relaxation Time (tau): {tau:.4f}\")\n",
    "\n",
    "# --- D2Q9 Lattice Constants ---\n",
    "# The 9 directions: Center, E, N, W, S, NE, NW, SW, SE\n",
    "w = np.array([4/9, 1/9, 1/9, 1/9, 1/9, 1/36, 1/36, 1/36, 1/36])\n",
    "c_x = np.array([0, 1, 0, -1, 0, 1, -1, -1, 1])\n",
    "c_y = np.array([0, 0, 1, 0, -1, 1, 1, -1, -1])\n",
    "\n",
    "# Create the Cylinder Mask (Boolean array)\n",
    "Y, X = np.meshgrid(np.arange(NY), np.arange(NX), indexing='ij')\n",
    "cylinder_mask = (X - CX)**2 + (Y - CY)**2 < R**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6038ea-a9b2-461d-b9f6-60d86ad76177",
   "metadata": {},
   "source": [
    "## The \"Legacy\" Approach (NumPy/CPU)\n",
    "\n",
    "The  current approach to prototyping relying on standard `numpy` operations. Note the explicit loop for streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba008c-8cfb-46a8-866b-07312b8bf11f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_numpy():\n",
    "    return np.ones((9, NY, NX)) * w[:, None, None]\n",
    "\n",
    "def step_numpy(f):\n",
    "    # 1. Macroscopic variables\n",
    "    rho = np.sum(f, axis=0)\n",
    "    # Dense linear algebra (slow on CPU)\n",
    "    ux = np.sum(f * c_x[:, None, None], axis=0) / rho\n",
    "    uy = np.sum(f * c_y[:, None, None], axis=0) / rho\n",
    "    \n",
    "    # 2. Collision (BGK approximation)\n",
    "    # Calculate Equilibrium\n",
    "    u_sq = ux**2 + uy**2\n",
    "    for i in range(9):\n",
    "        cu = c_x[i]*ux + c_y[i]*uy\n",
    "        f_eq = rho * w[i] * (1 + 3*cu + 4.5*cu**2 - 1.5*u_sq)\n",
    "        f[i] = f[i] - (f[i] - f_eq) / tau\n",
    "\n",
    "    # 3. Streaming (The Bottleneck)\n",
    "    # Rolling arrays in memory destroys CPU cache locality\n",
    "    for i in range(9):\n",
    "        f[i] = np.roll(f[i], shift=(c_x[i], c_y[i]), axis=(1, 0))\n",
    "\n",
    "    # 4. Boundary Conditions\n",
    "    # Rigid Cylinder (Bounce-back)\n",
    "    # Invert directions: e.g., North(2) becomes South(4)\n",
    "    inverse_idxs = [0, 3, 4, 1, 2, 7, 8, 5, 6]\n",
    "    for i in range(9):\n",
    "        # Wherever the mask is True, reflect the particle\n",
    "        f[i][cylinder_mask] = f[inverse_idxs[i]][cylinder_mask]\n",
    "        \n",
    "    # Inflow (Left side fixed velocity)\n",
    "    # (Simplified for brevity: force equilibrium at x=0)\n",
    "    col0_rho = np.sum(f[:, :, 0], axis=0)\n",
    "    col0_u_sq = U0**2\n",
    "    for i in range(9):\n",
    "        cu = c_x[i]*U0\n",
    "        f_eq_0 = col0_rho * w[i] * (1 + 3*cu + 4.5*cu**2 - 1.5*col0_u_sq)\n",
    "        f[i, :, 0] = f_eq_0\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b106e-394d-4bc0-a8dd-56af7143058f",
   "metadata": {},
   "source": [
    "## The Alternative Approach (JAX / TPU)\n",
    "\n",
    "The logic is identical, but we use jax.jit. This compiles the entire physics loop into a single fused XLA kernel. The roll becomes a tensor shift in High Bandwidth Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b55719-96e8-4f4e-883f-f1167b5a3848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Move constants to JAX Device (Immutable)\n",
    "J_w = jnp.array(w)\n",
    "J_cx = jnp.array(c_x)\n",
    "J_cy = jnp.array(c_y)\n",
    "J_mask = jnp.array(cylinder_mask)\n",
    "J_inv = jnp.array([0, 3, 4, 1, 2, 7, 8, 5, 6]) # Inversion mapping\n",
    "\n",
    "def init_jax():\n",
    "    return jnp.ones((9, NY, NX)) * J_w[:, None, None]\n",
    "\n",
    "@jax.jit  # <--- The Magic: Compiles Python to TPU Machine Code\n",
    "def step_jax(f):\n",
    "    # 1. Macroscopic variables\n",
    "    rho = jnp.sum(f, axis=0)\n",
    "    ux = jnp.sum(f * J_cx[:, None, None], axis=0) / rho\n",
    "    uy = jnp.sum(f * J_cy[:, None, None], axis=0) / rho\n",
    "\n",
    "    # 2. Collision (Vectorized)\n",
    "    u_sq = ux**2 + uy**2\n",
    "    # Einops-style calculation for all 9 directions at once\n",
    "    cu = (f * 0) # Placeholder for dot product broadcasting\n",
    "    # A fully vectorized equilibrium calculation\n",
    "    # (We expand dims to broadcast (9,) against (NY, NX))\n",
    "    cu = J_cx[:, None, None] * ux + J_cy[:, None, None] * uy\n",
    "    f_eq = rho * J_w[:, None, None] * (1 + 3*cu + 4.5*cu**2 - 1.5*u_sq)\n",
    "    \n",
    "    f_out = f - (f - f_eq) / tau\n",
    "\n",
    "    # 3. Streaming\n",
    "    # On TPU, jnp.roll is a hardware-optimized shift\n",
    "    for i in range(9):\n",
    "        f_out = f_out.at[i].set(jnp.roll(f_out[i], shift=(J_cx[i], J_cy[i]), axis=(1, 0)))\n",
    "\n",
    "    # 4. Boundary Conditions (Bounce-back)\n",
    "    # Where mask is True, replace f_out with the inverted direction from BEFORE stream\n",
    "    # (Standard LBM bounceback logic)\n",
    "    bounced = f_out[J_inv]\n",
    "    f_out = jnp.where(J_mask, bounced, f_out)\n",
    "    \n",
    "    # Inflow Condition\n",
    "    # (Re-enforce Equilibrium at Left Wall)\n",
    "    rho_0 = jnp.sum(f_out[:, :, 0], axis=0)\n",
    "    cu_0 = J_cx[:, None] * U0\n",
    "    f_eq_0 = rho_0 * J_w[:, None] * (1 + 3*cu_0 + 4.5*cu_0**2 - 1.5*U0**2)\n",
    "    f_out = f_out.at[:, :, 0].set(f_eq_0)\n",
    "\n",
    "    return f_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19d822-2ebf-40ac-85e7-12d2f459422b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Benchmark\n",
    "We run 100 iterations of both. Note: The first JAX run includes compilation time, so we ignore it (warmup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb9520-242c-4be8-9dc6-c47ca08adaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title 5. The Race: CPU vs TPU\n",
    "\n",
    "ITERATIONS = 500\n",
    "\n",
    "print(f\"Running {ITERATIONS} steps of Fluid Dynamics...\")\n",
    "\n",
    "# --- 1. Run NumPy ---\n",
    "f_state = init_numpy()\n",
    "start_cpu = time.time()\n",
    "for _ in range(ITERATIONS):\n",
    "    f_state = step_numpy(f_state)\n",
    "end_cpu = time.time()\n",
    "cpu_time = end_cpu - start_cpu\n",
    "print(f\"NumPy (CPU): {cpu_time:.2f} seconds | {(ITERATIONS/cpu_time):.2f} FPS\")\n",
    "\n",
    "# --- 2. Run JAX ---\n",
    "f_jax = init_jax()\n",
    "# WARMUP (Compiling)\n",
    "print(\"Compiling JAX Kernel (Warmup)...\")\n",
    "_ = step_jax(f_jax).block_until_ready()\n",
    "\n",
    "# THE REAL RUN\n",
    "start_tpu = time.time()\n",
    "# We use jax.lax.fori_loop for true 'simulation inside the chip'\n",
    "# But for a fair python-loop comparison, we'll loop in python\n",
    "for _ in range(ITERATIONS):\n",
    "    f_jax = step_jax(f_jax)\n",
    "# Force synchronization to measure actual time\n",
    "f_jax.block_until_ready()\n",
    "end_tpu = time.time()\n",
    "tpu_time = end_tpu - start_tpu\n",
    "\n",
    "print(f\"JAX (TPU)  : {tpu_time:.2f} seconds | {(ITERATIONS/tpu_time):.2f} FPS\")\n",
    "print(f\"Speedup    : {cpu_time/tpu_time:.1f}x FASTER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0670476-0c75-4065-88e6-62879fb25ca4",
   "metadata": {},
   "source": [
    "Even on CPU the speed-up from JAX should be evident.\n",
    "\n",
    "## Visualization\n",
    "Speed means nothing if the math is wrong. We calculate the Curl (Vorticity) of the velocity field to visualize the eddies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d656f9b-f7f3-4f36-82e2-2eeaa857c696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title 6. Visualize the Vorticity (The \"Pretty Picture\")\n",
    "\n",
    "def get_curl(f_final):\n",
    "    # Convert JAX array to Numpy for plotting\n",
    "    f = np.array(f_final)\n",
    "    rho = np.sum(f, axis=0)\n",
    "    ux = np.sum(f * c_x[:, None, None], axis=0) / rho\n",
    "    uy = np.sum(f * c_y[:, None, None], axis=0) / rho\n",
    "    \n",
    "    # Compute Curl (du_y/dx - du_x/dy) using gradients\n",
    "    dy_ux, dx_ux = np.gradient(ux)\n",
    "    dy_uy, dx_uy = np.gradient(uy)\n",
    "    curl = dx_uy - dy_ux\n",
    "    return curl\n",
    "\n",
    "vorticity = get_curl(f_jax)\n",
    "\n",
    "plt.figure(figsize=(20, 6), dpi=200)\n",
    "plt.imshow(vorticity, cmap='RdBu', vmin=-0.02, vmax=0.02, origin='lower')\n",
    "# Overlay Cylinder\n",
    "circle = plt.Circle((CX, CY), R, color='black', fill=True)\n",
    "plt.gca().add_patch(circle)\n",
    "\n",
    "plt.title(f\"Von Kármán Vortex Street (Re={Re})\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87327592-0338-4440-82e4-3b918aef827d",
   "metadata": {},
   "source": [
    "## The Code Difference: \n",
    "\n",
    "Note that step_jax is 95% identical to step_numpy. You don't need to learn a new language.\n",
    "\n",
    "`jnp.roll` is the streaming step. On a CPU, this is a slow memory copy. On a TPU, the interconnects move this data instantly. You should see a significat speedup even without resorting to a TPU.\n",
    "\n",
    "The Output: The visualization shows the alternating positive (Red) and negative (Blue) vortices trailing the cylinder. Run the cell below to view the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc201d6-7e3d-486c-bd04-2e9d7687c50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate Animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 1. COMPILE A \"BATCH\" STEP\n",
    "# To make rendering fast, we run 40 physics steps per video frame.\n",
    "# We JIT compile this loop so the TPU screams through the math.\n",
    "STEPS_PER_FRAME = 40\n",
    "\n",
    "@jax.jit\n",
    "def evolve_batch(f):\n",
    "    def body_fun(i, f_val):\n",
    "        return step_jax(f_val)\n",
    "    # This runs the loop inside the TPU, not in Python\n",
    "    return jax.lax.fori_loop(0, STEPS_PER_FRAME, body_fun, f)\n",
    "\n",
    "# 2. SETUP THE PLOT\n",
    "fig, ax = plt.subplots(figsize=(20, 6), dpi=200)\n",
    "\n",
    "# Initial Frame\n",
    "f_anim = init_jax()\n",
    "# Run a quick warmup to get past the initial \"still\" water\n",
    "for _ in range(5):\n",
    "    f_anim = evolve_batch(f_anim)\n",
    "\n",
    "# Compute initial curl for the color scale\n",
    "initial_curl = get_curl(f_anim)\n",
    "im = ax.imshow(initial_curl, cmap='RdBu', vmin=-0.02, vmax=0.02, \n",
    "               origin='lower', interpolation='spline36')\n",
    "\n",
    "# Add the cylinder visual\n",
    "circle = plt.Circle((CX, CY), R, color='black', fill=True)\n",
    "ax.add_patch(circle)\n",
    "ax.axis('off')\n",
    "title = ax.set_title(\"Time Step: 0\")\n",
    "\n",
    "# 3. ANIMATION LOOP\n",
    "def animate(frame_num):\n",
    "    global f_anim\n",
    "    # Run the physics on TPU\n",
    "    f_anim = evolve_batch(f_anim)\n",
    "    f_anim.block_until_ready() # Wait for TPU to finish\n",
    "    \n",
    "    # Bring result to CPU for plotting\n",
    "    curl = get_curl(f_anim)\n",
    "    \n",
    "    # Update the image\n",
    "    im.set_data(curl)\n",
    "    title.set_text(f\"Time Step: {frame_num * STEPS_PER_FRAME}\")\n",
    "    return [im, title]\n",
    "\n",
    "# Create animation (100 frames * 40 steps = 4000 simulation steps)\n",
    "print(\"Rendering video... (This might take 30-60 seconds)\")\n",
    "anim = animation.FuncAnimation(fig, animate, frames=100, interval=50, blit=True)\n",
    "\n",
    "# Display as interactive HTML5 video\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518945c-6f74-4da7-ab9b-2ccfc75b83ae",
   "metadata": {},
   "source": [
    "## Download mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667ee6f-b2ba-48f7-8d83-be4c2f20e25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# 1. ROBUST INSTALLATION\n",
    "# Try Conda first (preferred for your environment), then apt-get\n",
    "if os.system(\"which ffmpeg\") != 0:\n",
    "    print(\"⚠️ FFmpeg not found. Attempting install via Conda...\")\n",
    "    # This works better in Vertex AI / JupyterLab environments\n",
    "    result = os.system(\"conda install -c conda-forge ffmpeg -y\")\n",
    "    \n",
    "    if result != 0:\n",
    "        print(\"Conda install failed. Trying system apt-get...\")\n",
    "        !sudo apt-get update && sudo apt-get install ffmpeg -y > /dev/null\n",
    "\n",
    "# Verify installation\n",
    "if os.system(\"which ffmpeg\") != 0:\n",
    "    raise RuntimeError(\"❌ FFmpeg could not be installed. Please install it manually to save MP4s.\")\n",
    "else:\n",
    "    print(\"✅ FFmpeg is installed and ready.\")\n",
    "\n",
    "# 2. SAVE THE VIDEO\n",
    "output_filename = \"tpu_fluid_simulation.mp4\"\n",
    "print(f\"Rendering {output_filename}...\")\n",
    "\n",
    "# We explicitly create the writer object.\n",
    "# This prevents the 'silent fallback' to Pillow that caused your error.\n",
    "FFwriter = animation.FFMpegWriter(\n",
    "    fps=30, \n",
    "    extra_args=['-vcodec', 'libx264']\n",
    ")\n",
    "\n",
    "try:\n",
    "    anim.save(output_filename, writer=FFwriter)\n",
    "    print(f\"✅ Video saved successfully: {output_filename}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Error: Matplotlib still cannot find the 'ffmpeg' binary.\")\n",
    "    print(\"Try restarting the kernel to refresh system paths.\")\n",
    "\n",
    "# 3. TRIGGER DOWNLOAD\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_filename)\n",
    "except ImportError:\n",
    "    print(\"Click below to download:\")\n",
    "    display(FileLink(output_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb01a6-3940-44a7-bef0-bb058c0f2668",
   "metadata": {},
   "source": [
    "# The \"Fun\" Stuff: Topology Optmization\n",
    "\n",
    "In traditional CFD, optimizing a shape (e.g., \"what shape of wing minimizes drag?\") is challenging. You usually have to write a completely separate \"Adjoint Solver\" or just guess-and-check 1,000 times.\n",
    "\n",
    "In JAX, because the simulation is differentiable, we can get the answer automatically.\n",
    "\n",
    "We are going to ask the TPU:\n",
    "\n",
    "\"Here is the flow. Tell me exactly which pixels on the screen I should turn into 'solid wall' to stop the turbulence.\"\n",
    "\n",
    "\n",
    "## The Setup: \"Soft Solver\"\n",
    "\n",
    "To make the physics differentiable, we have to make the solid cylinder \"soft.\" Instead of a hard True/False mask, we treat the obstacle like a porous fog (values between 0.0 and 1.0). This allows JAX to calculate gradients through the object.\n",
    "\n",
    "Note:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5b632-ddae-4828-89e4-bd64b7198b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. DIFFERENTIABLE SOLVER\n",
    "@jax.jit\n",
    "def step_differentiable(f, continuous_mask):\n",
    "    # Standard Macros\n",
    "    rho = jnp.sum(f, axis=0)\n",
    "    ux = jnp.sum(f * J_cx[:, None, None], axis=0) / rho\n",
    "    uy = jnp.sum(f * J_cy[:, None, None], axis=0) / rho\n",
    "\n",
    "    # Standard Collision\n",
    "    u_sq = ux**2 + uy**2\n",
    "    cu = J_cx[:, None, None] * ux + J_cy[:, None, None] * uy\n",
    "    f_eq = rho * J_w[:, None, None] * (1 + 3*cu + 4.5*cu**2 - 1.5*u_sq)\n",
    "    f_post_collision = f - (f - f_eq) / tau\n",
    "\n",
    "    # Standard Streaming\n",
    "    f_streamed = f_post_collision\n",
    "    for i in range(9):\n",
    "        f_streamed = f_streamed.at[i].set(\n",
    "            jnp.roll(f_streamed[i], shift=(J_cx[i], J_cy[i]), axis=(1, 0))\n",
    "        )\n",
    "\n",
    "    # SOFT INTERACTION\n",
    "    # Use continuous_mask (0.0 to 1.0) to blend bounce-back vs stream\n",
    "    f_bounced = f_streamed[J_inv]\n",
    "    f_out = continuous_mask * f_bounced + (1.0 - continuous_mask) * f_streamed\n",
    "\n",
    "    # Inflow BC\n",
    "    rho_0 = jnp.sum(f_out[:, :, 0], axis=0)\n",
    "    cu_0 = J_cx[:, None] * U0\n",
    "    f_eq_0 = rho_0 * J_w[:, None] * (1 + 3*cu_0 + 4.5*cu_0**2 - 1.5*U0**2)\n",
    "    f_out = f_out.at[:, :, 0].set(f_eq_0)\n",
    "    \n",
    "    return f_out\n",
    "\n",
    "\n",
    "def init_moving_jax():\n",
    "    # Calculate equilibrium for velocity U0\n",
    "    rho_start = 1.0\n",
    "    cu = J_cx[:, None, None] * U0\n",
    "    u_sq = U0**2\n",
    "    f_single_pixel = rho_start * J_w[:, None, None] * (1 + 3*cu + 4.5*cu**2 - 1.5*u_sq)\n",
    "    \n",
    "    # EXPLICITLY expand to full grid (9, NY, NX)\n",
    "    # This prevents the Shape Mismatch error in lax.scan\n",
    "    return jnp.broadcast_to(f_single_pixel, (9, NY, NX))\n",
    "\n",
    "# 2. LOSS FUNCTION\n",
    "def simulation_loss(mask_proposal):\n",
    "    # Start with MOVING fluid\n",
    "    f = init_moving_jax()\n",
    "    \n",
    "    # Run loop\n",
    "    def loop_body(f_curr, _):\n",
    "        f_next = step_differentiable(f_curr, mask_proposal)\n",
    "        return f_next, None\n",
    "    \n",
    "    # Run 400 steps\n",
    "    f_final, _ = jax.lax.scan(loop_body, f, jnp.arange(400)) \n",
    "    \n",
    "    # Calculate Turbulence (Curl squared)\n",
    "    rho = jnp.sum(f_final, axis=0)\n",
    "    ux = jnp.sum(f_final * J_cx[:, None, None], axis=0) / rho\n",
    "    uy = jnp.sum(f_final * J_cy[:, None, None], axis=0) / rho\n",
    "    \n",
    "    dy_ux = jnp.gradient(ux, axis=0)\n",
    "    dx_uy = jnp.gradient(uy, axis=1)\n",
    "    curl = dx_uy - dy_ux\n",
    "    \n",
    "    return jnp.sum(curl**2)\n",
    "\n",
    "# 3. CALCULATE GRADIENTS\n",
    "print(\"Computing Adjoint Gradient (Simulating backwards)...\")\n",
    "\n",
    "# Convert boolean cylinder to float\n",
    "current_geometry = jnp.array(cylinder_mask, dtype=jnp.float32)\n",
    "\n",
    "# Get gradients\n",
    "grad_fn = jax.grad(simulation_loss)\n",
    "sensitivity_map = grad_fn(current_geometry)\n",
    "\n",
    "# Force computation\n",
    "sensitivity_map_np = np.array(sensitivity_map)\n",
    "print(f\"Gradient stats: Min={sensitivity_map_np.min():.2e}, Max={sensitivity_map_np.max():.2e}\")\n",
    "\n",
    "# 4. VISUALIZATION\n",
    "plt.figure(figsize=(18, 6), dpi=150)\n",
    "\n",
    "# Robust limit calculation\n",
    "abs_max = np.max(np.abs(sensitivity_map_np))\n",
    "limit = abs_max * 0.8 if abs_max > 1e-9 else 1.0 \n",
    "\n",
    "im = plt.imshow(sensitivity_map_np, cmap='seismic', vmin=-limit, vmax=limit, origin='lower')\n",
    "\n",
    "# Outline the cylinder\n",
    "plt.contour(cylinder_mask, levels=[0.5], colors='black', linewidths=2)\n",
    "\n",
    "plt.title(\"The 'Adjoint' Map: Red = Adds Turbulence / Blue = Reduces Turbulence\", fontsize=14)\n",
    "plt.colorbar(im, label=\"Sensitivity (dLoss/dGeometry)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887674c-3a16-4df7-aabc-cebf0cc1da9d",
   "metadata": {},
   "source": [
    "**Download the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216acf2-e007-4e9c-a63a-ed2fe5ec1368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title 10. Save & Download Adjoint Map Image\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# 1. Save the current figure\n",
    "# bbox_inches='tight' removes the white margins\n",
    "output_image = \"adjoint_sensitivity_map.png\"\n",
    "print(f\"Saving {output_image}...\")\n",
    "plt.savefig(output_image, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# 2. Trigger Download\n",
    "try:\n",
    "    # Google Colab specific download trigger\n",
    "    from google.colab import files\n",
    "    files.download(output_image)\n",
    "except ImportError:\n",
    "    # For local Jupyter/JupyterLab, generate a clickable link\n",
    "    print(f\"✅ Image saved locally as '{output_image}'\")\n",
    "    display(FileLink(output_image))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m138",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m138"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
